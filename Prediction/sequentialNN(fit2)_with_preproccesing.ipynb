{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"swarmNN(fit2).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NMlaGnXlmJnK","colab_type":"text"},"source":["iPython Notebook based on the R code wich was provided by the team around Joachim L. Schulzte. The team wrote the \"[Scalable Prediction of Acute Myeloid Leukemia Using High-Dimensional Machine Learning and Blood Transcriptomics](https://www.cell.com/action/showPdf?pii=S2589-0042%2819%2930525-5)\" paper.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FhFoub4Ln7Sh","colab_type":"text"},"source":["## 1. Imports"]},{"cell_type":"code","metadata":{"id":"6sSuYeuJk_Ok","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":100},"outputId":"f6657a5e-d1ab-4815-e0f5-b88434020e4f"},"source":["# Importing Libraries\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.regularizers import l1_l2\n","from keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"7ucyFNnGqSw_","colab_type":"text"},"source":["## 2. Obtaining the data"]},{"cell_type":"code","metadata":{"id":"zYxBrPCA0gmd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":128},"outputId":"832e676d-06bb-41c7-d60e-1c06447b1185"},"source":["# Mounting a google drive, in which the data should be stored in .csv format\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OSNg7N_vwp1q","colab_type":"code","colab":{}},"source":["# Reading Data from the google drive\n","\n","# df1 = pd.read_csv(\"/content/drive/My Drive/TranscriptomicData/data1.csv\")\n","# info1 = pd.read_csv(\"/content/drive/My Drive/TranscriptomicData/info1.csv\")\n","df2 = pd.read_csv(\"/content/drive/My Drive/TranscriptomicData/data2.csv\")\n","info2 = pd.read_csv(\"/content/drive/My Drive/TranscriptomicData/info2.csv\")\n","# df3 = pd.read_csv(\"/content/drive/My Drive/TranscriptomicData/data3.csv\")\n","# info3 = pd.read_csv(\"/content/drive/My Drive/TranscriptomicData/info3.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCxY1dWp3ud4","colab_type":"code","colab":{}},"source":["# Choosing data\n","\n","data = df2\n","target = info2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1cenrwGPqgsc","colab_type":"text"},"source":["## 3. Cleaning the data "]},{"cell_type":"code","metadata":{"id":"CyJrCJ87wqbK","colab_type":"code","colab":{}},"source":["# Cleaning of the data\n","\n","data = data.rename(columns = {'Unnamed: 0':'Gene'})\n","data = data.T\n","data = data.rename(columns=data.iloc[0])\n","data.index.names = ['Sample']\n","data = data.iloc[1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WlB23YRgTLLm","colab_type":"code","colab":{}},"source":["# data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CeT0BYatwtLQ","colab_type":"code","colab":{}},"source":["# data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vV1EHSTq5pl","colab_type":"code","colab":{}},"source":["# Cleaning of the target data\n","\n","target = target.rename(columns = {'Unnamed: 0':'Sample'})\n","target = target.set_index(\"Sample\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ataaV7vgxvhB","colab_type":"code","colab":{}},"source":["# target.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lrobdh8Bxwyv","colab_type":"code","colab":{}},"source":["# target.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OA44veSa3Hhc","colab_type":"code","colab":{}},"source":["# Joining the data and the target data and cleaning it\n","\n","dt = data.join(target)\n","dt = dt.drop(columns=['Dataset', 'GSE', 'Disease', 'Tissue', 'FAB', 'Filename', 'FAB_all'])\n","dt.Condition = dt.Condition.map(dict(CASE=1, CONTROL=0))\n","dt = dt.astype('int64')\n","dt = dt.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9PGZdw8k7IGh","colab_type":"code","colab":{}},"source":["# dt.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"22CLTFnZ7KZo","colab_type":"code","colab":{}},"source":["# dt.head ()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SoZvgf0l3CWD","colab_type":"text"},"source":["## 4. Preparing the data\n"]},{"cell_type":"code","metadata":{"id":"ciT86-2ay1BS","colab_type":"code","colab":{}},"source":["# Splitting the data into source (X) and target (y) variables\n","\n","X = dt.drop(['Condition'], axis=1)\n","y = dt['Condition']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYfY4jzTypq7","colab_type":"code","colab":{}},"source":["# Normalizing the source data\n","\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","X = pd.DataFrame(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMfZ7Xah8zwh","colab_type":"code","colab":{}},"source":["# X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x804Sd4h8146","colab_type":"code","colab":{}},"source":["# X.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCMcd03X87tl","colab_type":"code","colab":{}},"source":["# Splitting the Data in train (80%) and test (20%)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LanTawQ_VBjp","colab_type":"text"},"source":["## 5. Model training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FWB4u9IHTk5-","colab":{}},"source":["# Defining some parameters\n","\n","r = X_train.shape[0]  # number of rows\n","c = X_train.shape[1] # number of columns \n","epochs = 100\n","batch_size = 512\n","num_nodes = 1024\n","dropout_rate = 0.3\n","l1_v = 0.0\n","l2_v = 0.005\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JZ343ZPyS2yX","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"93627976-b6c3-43b0-8956-74f920bd2836"},"source":["# NN (fit2 in Paper)\n","\n","model = Sequential()\n","#input layer\n","model.add(Dense(256, activation='relu', kernel_regularizer = l1_l2(l1=0.0, l2=0.0), input_dim=c))\n","model.add(Dropout(0.4))\n","\n","# first layer\n","model.add(Dense(num_nodes, activation='relu', kernel_regularizer = l1_l2(l1=l1_v, l2=l2_v), input_dim=c))\n","model.add(Dropout(dropout_rate))\n","# second layer\n","model.add(Dense(int(num_nodes / 2), activation='relu', kernel_regularizer = l1_l2(l1=l1_v, l2=l2_v), input_dim=c))\n","model.add(Dropout(dropout_rate))\n","# third layer\n","model.add(Dense(int(num_nodes / 2), activation='relu', kernel_regularizer = l1_l2(l1=l1_v, l2=l2_v), input_dim=c))\n","model.add(Dropout(dropout_rate))\n","# fourth layer\n","model.add(Dense(int(num_nodes / 4), activation='relu', kernel_regularizer = l1_l2(l1=l1_v, l2=l2_v), input_dim=c))\n","model.add(Dropout(dropout_rate))\n","# fifth layer\n","model.add(Dense(int(num_nodes / 4), activation='relu', kernel_regularizer = l1_l2(l1=l1_v, l2=l2_v), input_dim=c))\n","model.add(Dropout(dropout_rate))\n","# sixth layer\n","model.add(Dense(int(num_nodes / 8), activation='relu', kernel_regularizer = l1_l2(l1=l1_v, l2=l2_v), input_dim=c))\n","model.add(Dropout(dropout_rate))\n","# seventh layer\n","model.add(Dense(int(num_nodes / 8), activation='relu', kernel_regularizer = l1_l2(l1=l1_v, l2=l2_v), input_dim=c))\n","model.add(Dropout(dropout_rate))\n","# eighth layer\n","model.add(Dense(int(num_nodes / 16), activation='relu', kernel_regularizer = l1_l2(l1=l1_v, l2=l2_v), input_dim=c))\n","model.add(Dropout(dropout_rate))\n","\n","# output layer\n","model.add(Dense(units = 1, activation = \"tanh\"))\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 256)               3253504   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              263168    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 512)               524800    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 128)               16512     \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 1)                 65        \n","=================================================================\n","Total params: 4,558,977\n","Trainable params: 4,558,977\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"puJu2ALxS2yg","colab":{}},"source":["# Creating a callback that implements early stopping if the loss function decreases and saves the best model based on the loss function in the h5 format in the mounted drive.\n","\n","callbacks = [EarlyStopping(monitor='loss', patience=25),\n","         ModelCheckpoint(filepath='/content/drive/My Drive/TranscriptomicData/best_model_fit2.h5', monitor='loss', save_best_only=True)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DKuAu9hbS2yj","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2d065d26-08b6-4277-e667-4459e8e52ba6"},"source":["# Training the model\n","model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=callbacks)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/100\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","6678/6678 [==============================] - 11s 2ms/step - loss: 14.6972 - acc: 0.5037\n","Epoch 2/100\n","6678/6678 [==============================] - 1s 204us/step - loss: 13.4214 - acc: 0.5500\n","Epoch 3/100\n","6678/6678 [==============================] - 1s 210us/step - loss: 11.9641 - acc: 0.5067\n","Epoch 4/100\n","6678/6678 [==============================] - 1s 210us/step - loss: 10.8958 - acc: 0.4197\n","Epoch 5/100\n","6678/6678 [==============================] - 1s 208us/step - loss: 10.3369 - acc: 0.3226\n","Epoch 6/100\n","6678/6678 [==============================] - 1s 216us/step - loss: 9.6678 - acc: 0.3214\n","Epoch 7/100\n","6678/6678 [==============================] - 1s 209us/step - loss: 9.2469 - acc: 0.3089\n","Epoch 8/100\n","6678/6678 [==============================] - 1s 206us/step - loss: 8.7707 - acc: 0.3145\n","Epoch 9/100\n","6678/6678 [==============================] - 1s 205us/step - loss: 8.3494 - acc: 0.3155\n","Epoch 10/100\n","6678/6678 [==============================] - 1s 209us/step - loss: 7.9452 - acc: 0.3284\n","Epoch 11/100\n","6678/6678 [==============================] - 1s 208us/step - loss: 7.5440 - acc: 0.3459\n","Epoch 12/100\n","6678/6678 [==============================] - 1s 208us/step - loss: 7.2236 - acc: 0.3633\n","Epoch 13/100\n","6678/6678 [==============================] - 1s 210us/step - loss: 6.9171 - acc: 0.3922\n","Epoch 14/100\n","6678/6678 [==============================] - 1s 210us/step - loss: 6.6390 - acc: 0.4298\n","Epoch 15/100\n","6678/6678 [==============================] - 1s 208us/step - loss: 6.4180 - acc: 0.3486\n","Epoch 16/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 6.1461 - acc: 0.3678\n","Epoch 17/100\n","6678/6678 [==============================] - 1s 205us/step - loss: 5.9154 - acc: 0.3844\n","Epoch 18/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 5.6911 - acc: 0.3769\n","Epoch 19/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 5.4508 - acc: 0.4211\n","Epoch 20/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 5.2937 - acc: 0.3790\n","Epoch 21/100\n","6678/6678 [==============================] - 1s 215us/step - loss: 5.0997 - acc: 0.3504\n","Epoch 22/100\n","6678/6678 [==============================] - 1s 219us/step - loss: 4.9185 - acc: 0.3535\n","Epoch 23/100\n","6678/6678 [==============================] - 1s 212us/step - loss: 4.7251 - acc: 0.3807\n","Epoch 24/100\n","6678/6678 [==============================] - 1s 218us/step - loss: 4.5749 - acc: 0.3874\n","Epoch 25/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 4.4000 - acc: 0.5371\n","Epoch 26/100\n","6678/6678 [==============================] - 1s 209us/step - loss: 4.2600 - acc: 0.5367\n","Epoch 27/100\n","6678/6678 [==============================] - 1s 213us/step - loss: 4.1237 - acc: 0.4119\n","Epoch 28/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 3.9649 - acc: 0.4185\n","Epoch 29/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 3.8324 - acc: 0.4494\n","Epoch 30/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 3.7049 - acc: 0.4940\n","Epoch 31/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 3.5949 - acc: 0.6050\n","Epoch 32/100\n","6678/6678 [==============================] - 1s 217us/step - loss: 3.4888 - acc: 0.6135\n","Epoch 33/100\n","6678/6678 [==============================] - 1s 209us/step - loss: 3.3605 - acc: 0.6580\n","Epoch 34/100\n","6678/6678 [==============================] - 1s 208us/step - loss: 3.2670 - acc: 0.7053\n","Epoch 35/100\n","6678/6678 [==============================] - 1s 216us/step - loss: 3.4484 - acc: 0.6872\n","Epoch 36/100\n","6678/6678 [==============================] - 1s 217us/step - loss: 3.2281 - acc: 0.7113\n","Epoch 37/100\n","6678/6678 [==============================] - 1s 220us/step - loss: 3.0894 - acc: 0.7038\n","Epoch 38/100\n","6678/6678 [==============================] - 1s 215us/step - loss: 2.9953 - acc: 0.8110\n","Epoch 39/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 2.9275 - acc: 0.6809\n","Epoch 40/100\n","6678/6678 [==============================] - 1s 217us/step - loss: 2.8345 - acc: 0.7465\n","Epoch 41/100\n","6678/6678 [==============================] - 1s 216us/step - loss: 2.7407 - acc: 0.7496\n","Epoch 42/100\n","6678/6678 [==============================] - 2s 228us/step - loss: 2.6391 - acc: 0.7475\n","Epoch 43/100\n","6678/6678 [==============================] - 1s 214us/step - loss: 2.5610 - acc: 0.7516\n","Epoch 44/100\n","6678/6678 [==============================] - 1s 210us/step - loss: 2.4740 - acc: 0.8720\n","Epoch 45/100\n","6678/6678 [==============================] - 1s 212us/step - loss: 2.4017 - acc: 0.8826\n","Epoch 46/100\n","6678/6678 [==============================] - 1s 224us/step - loss: 2.3541 - acc: 0.8615\n","Epoch 47/100\n","6678/6678 [==============================] - 1s 214us/step - loss: 2.2686 - acc: 0.9122\n","Epoch 48/100\n","6678/6678 [==============================] - 1s 210us/step - loss: 2.2169 - acc: 0.9111\n","Epoch 49/100\n","6678/6678 [==============================] - 1s 212us/step - loss: 2.1433 - acc: 0.9536\n","Epoch 50/100\n","6678/6678 [==============================] - 1s 209us/step - loss: 2.0929 - acc: 0.9711\n","Epoch 51/100\n","6678/6678 [==============================] - 1s 208us/step - loss: 2.0329 - acc: 0.9745\n","Epoch 52/100\n","6678/6678 [==============================] - 1s 208us/step - loss: 1.9686 - acc: 0.9739\n","Epoch 53/100\n","6678/6678 [==============================] - 1s 202us/step - loss: 1.9209 - acc: 0.9937\n","Epoch 54/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 1.8653 - acc: 0.9930\n","Epoch 55/100\n","6678/6678 [==============================] - 1s 212us/step - loss: 1.8130 - acc: 0.9925\n","Epoch 56/100\n","6678/6678 [==============================] - 1s 208us/step - loss: 1.7640 - acc: 0.9940\n","Epoch 57/100\n","6678/6678 [==============================] - 1s 220us/step - loss: 1.7170 - acc: 0.9967\n","Epoch 58/100\n","6678/6678 [==============================] - 1s 210us/step - loss: 1.6803 - acc: 0.9943\n","Epoch 59/100\n","6678/6678 [==============================] - 1s 210us/step - loss: 1.6452 - acc: 0.9934\n","Epoch 60/100\n","6678/6678 [==============================] - 1s 212us/step - loss: 1.5965 - acc: 0.9955\n","Epoch 61/100\n","6678/6678 [==============================] - 1s 213us/step - loss: 1.5663 - acc: 0.9951\n","Epoch 62/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 1.5186 - acc: 0.9964\n","Epoch 63/100\n","6678/6678 [==============================] - 1s 210us/step - loss: 1.5170 - acc: 0.9913\n","Epoch 64/100\n","6678/6678 [==============================] - 1s 212us/step - loss: 1.4556 - acc: 0.9942\n","Epoch 65/100\n","6678/6678 [==============================] - 1s 219us/step - loss: 1.4146 - acc: 0.9969\n","Epoch 66/100\n","6678/6678 [==============================] - 1s 222us/step - loss: 1.3734 - acc: 0.9982\n","Epoch 67/100\n","6678/6678 [==============================] - 1s 222us/step - loss: 1.3418 - acc: 0.9979\n","Epoch 68/100\n","6678/6678 [==============================] - 1s 220us/step - loss: 1.3121 - acc: 0.9967\n","Epoch 69/100\n","6678/6678 [==============================] - 1s 222us/step - loss: 1.2767 - acc: 0.9969\n","Epoch 70/100\n","6678/6678 [==============================] - 1s 223us/step - loss: 1.2447 - acc: 0.9979\n","Epoch 71/100\n","6678/6678 [==============================] - 2s 225us/step - loss: 1.2140 - acc: 0.9978\n","Epoch 72/100\n","6678/6678 [==============================] - 1s 219us/step - loss: 1.1811 - acc: 0.9984\n","Epoch 73/100\n","6678/6678 [==============================] - 1s 219us/step - loss: 1.1550 - acc: 0.9987\n","Epoch 74/100\n","6678/6678 [==============================] - 1s 222us/step - loss: 1.1273 - acc: 0.9987\n","Epoch 75/100\n","6678/6678 [==============================] - 1s 219us/step - loss: 1.1009 - acc: 0.9990\n","Epoch 76/100\n","6678/6678 [==============================] - 1s 219us/step - loss: 1.0776 - acc: 0.9987\n","Epoch 77/100\n","6678/6678 [==============================] - 2s 226us/step - loss: 1.0512 - acc: 0.9984\n","Epoch 78/100\n","6678/6678 [==============================] - 1s 219us/step - loss: 1.0267 - acc: 0.9985\n","Epoch 79/100\n","6678/6678 [==============================] - 1s 224us/step - loss: 1.0082 - acc: 0.9987\n","Epoch 80/100\n","6678/6678 [==============================] - 1s 219us/step - loss: 0.9808 - acc: 0.9988\n","Epoch 81/100\n","6678/6678 [==============================] - 1s 224us/step - loss: 0.9601 - acc: 0.9984\n","Epoch 82/100\n","6678/6678 [==============================] - 2s 226us/step - loss: 0.9499 - acc: 0.9952\n","Epoch 83/100\n","6678/6678 [==============================] - 1s 218us/step - loss: 0.9299 - acc: 0.9978\n","Epoch 84/100\n","6678/6678 [==============================] - 1s 215us/step - loss: 0.9015 - acc: 0.9975\n","Epoch 85/100\n","6678/6678 [==============================] - 1s 216us/step - loss: 0.8858 - acc: 0.9984\n","Epoch 86/100\n","6678/6678 [==============================] - 1s 215us/step - loss: 0.8637 - acc: 0.9988\n","Epoch 87/100\n","6678/6678 [==============================] - 1s 217us/step - loss: 0.8453 - acc: 0.9988\n","Epoch 88/100\n","6678/6678 [==============================] - 1s 216us/step - loss: 0.8275 - acc: 0.9975\n","Epoch 89/100\n","6678/6678 [==============================] - 1s 211us/step - loss: 0.8102 - acc: 0.9981\n","Epoch 90/100\n","6678/6678 [==============================] - 1s 213us/step - loss: 0.7914 - acc: 0.9987\n","Epoch 91/100\n","6678/6678 [==============================] - 1s 217us/step - loss: 0.7731 - acc: 0.9991\n","Epoch 92/100\n","6678/6678 [==============================] - 2s 225us/step - loss: 0.7536 - acc: 0.9991\n","Epoch 93/100\n","6678/6678 [==============================] - 1s 217us/step - loss: 0.7408 - acc: 0.9985\n","Epoch 94/100\n","6678/6678 [==============================] - 1s 214us/step - loss: 0.7233 - acc: 0.9991\n","Epoch 95/100\n","6678/6678 [==============================] - 1s 214us/step - loss: 0.7071 - acc: 0.9991\n","Epoch 96/100\n","6678/6678 [==============================] - 1s 216us/step - loss: 0.6928 - acc: 0.9994\n","Epoch 97/100\n","6678/6678 [==============================] - 1s 218us/step - loss: 0.6805 - acc: 0.9991\n","Epoch 98/100\n","6678/6678 [==============================] - 1s 213us/step - loss: 0.6635 - acc: 0.9994\n","Epoch 99/100\n","6678/6678 [==============================] - 1s 215us/step - loss: 0.6501 - acc: 0.9993\n","Epoch 100/100\n","6678/6678 [==============================] - 1s 213us/step - loss: 0.6369 - acc: 0.9991\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f54856a8e80>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c6BikCDrS2yn","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"690733e5-383b-4350-b77b-f66602b5b59f"},"source":["# Evaluating the score the of the model against unseen data\n","\n","score = model.evaluate(X_test, y_test, verbose = 0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss: 0.6700315555412613\n","Test accuracy: 0.9934131736526947\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aDJ_KuUXS2yq","colab":{}},"source":["#plot_model(model)"],"execution_count":null,"outputs":[]}]}